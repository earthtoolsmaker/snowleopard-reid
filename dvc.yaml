stages:
  reorganize_locations:
    cmd: >-
      uv run python scripts/data/reorganize_locations.py
      --input-dir data/01_raw/locations
      --output-dir data/02_processed/locations
      --config-dir data/02_processed/config
    deps:
      - scripts/data/reorganize_locations.py
      - data/01_raw/locations
      - data/02_processed/config/naryn/individuals.yaml
      - data/02_processed/config/naryn/mappings.yaml
      - data/02_processed/config/sarychat/individuals.yaml
      - data/02_processed/config/sarychat/mappings.yaml
    outs:
      - data/02_processed/locations
    desc: "Reorganize snow leopard images from raw data into processed structure using canonical individual configs"

  grounding_dino_detection:
    cmd: >-
      uv run python scripts/models/grounding_dino.py
      --input-dir data/02_processed/locations
      --output-dir data/05_model_output/grounding_dino
      --text-prompt "a snow leopard."
      --model-id IDEA-Research/grounding-dino-base
      --box-threshold 0.30
      --text-threshold 0.20
    deps:
      - scripts/models/grounding_dino.py
      - data/02_processed/locations
    outs:
      - data/05_model_output/grounding_dino
    desc: "Detect snow leopards in images using GroundingDINO zero-shot object detection"

  sam_hq_segmentation:
    cmd: >-
      uv run python scripts/models/sam_hq.py
      --input-dir data/02_processed/locations
      --predictions-dir data/05_model_output/grounding_dino/predictions
      --output-dir data/05_model_output/sam_hq
      --checkpoint data/04_models/SAM_HQ/sam_hq_vit_l.pth
      --model-type vit_l
    deps:
      - scripts/models/sam_hq.py
      - data/02_processed/locations
      - data/05_model_output/grounding_dino
      - data/04_models/SAM_HQ/sam_hq_vit_l.pth
    outs:
      - data/05_model_output/sam_hq
    desc: "Generate high-quality segmentation masks using SAM HQ vit_l (Large) with GroundingDINO bounding boxes as prompts"

  crop_masks:
    cmd: >-
      uv run python scripts/data/crop_leopard_masks.py
      --sam-output-dir data/05_model_output/sam_hq
      --output-dir data/02_processed/cropped/leopards
      --padding 10
    deps:
      - scripts/data/crop_leopard_masks.py
      - data/05_model_output/sam_hq
    outs:
      - data/02_processed/cropped/leopards
    desc: "Crop individual snow leopards from images using SAM HQ masks with black background for downstream processing"

  yolo_prepare_dataset:
    cmd: >-
      uv run python scripts/data/sam_to_yolo.py
      --sam-output-dir ./data/05_model_output/sam_hq
      --yolo-output-dir ./data/02_processed/yolo/segmentation
      --min-area 200
      --max-size 1024
    deps:
      - ./data/05_model_output/sam_hq
      - ./scripts/data/sam_to_yolo.py
    outs:
      - ./data/02_processed/yolo/segmentation
    desc: "Convert SAM HQ binary masks to YOLO polygon format for segmentation dataset preparation"

  split_yolo_dataset:
    cmd: >-
      uv run python scripts/data/split_yolo_dataset.py
      --input-curated-json ./data/02_processed/fiftyone/yolo/segmentation/fiftyone_curated_selection.json
      --output-dir ./data/03_model_input/yolo/segmentation
      --random-seed 42
      --train-ratio 0.8
      --val-ratio 0.1
      --test-ratio 0.1
    deps:
      - ./data/02_processed/fiftyone/yolo/segmentation/fiftyone_curated_selection.json
      - ./scripts/data/split_yolo_dataset.py
    outs:
      - ./data/03_model_input/yolo/segmentation
    desc: "Split curated YOLO dataset into train/val/test with temporal anti-leakage"

  train_yolo_segmentation_baseline:
    cmd: >-
      uv run python scripts/models/train_yolo_segmentation.py
      --data-yaml ./data/03_model_input/yolo/segmentation/data.yaml
      --output-dir ./data/04_models/yolo/segmentation/baseline
      --model yolo11n-seg
      --epochs 10
      --batch-size 32
      --imgsz 640
    deps:
      - ./data/03_model_input/yolo/segmentation
      - ./scripts/models/train_yolo_segmentation.py
    outs:
      - ./data/04_models/yolo/segmentation/baseline
    desc: "Train baseline YOLO11n segmentation model (fast, 10 epochs, 640px)"

  train_yolo_segmentation_best:
    cmd: >-
      uv run python scripts/models/train_yolo_segmentation.py
      --data-yaml ./data/03_model_input/yolo/segmentation/data.yaml
      --output-dir ./data/04_models/yolo/segmentation/best
      --model yolo11n-seg
      --epochs 30
      --batch-size 16
      --imgsz 1280
      --fliplr 0.5
      --scale 0.7
      --translate 0.2
      --lr0 0.02
      --lrf 0.01
      --warmup-epochs 5
      --patience 50
    deps:
      - ./data/03_model_input/yolo/segmentation
      - ./scripts/models/train_yolo_segmentation.py
    outs:
      - ./data/04_models/yolo/segmentation/best
    desc: "Train optimized YOLO11n segmentation model (30 epochs, 1280px, lr0=0.02 for faster convergence)"
